{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>desc</th>\n",
       "      <th>zip</th>\n",
       "      <th>title</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>twp</th>\n",
       "      <th>addr</th>\n",
       "      <th>e</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.297876</td>\n",
       "      <td>-75.581294</td>\n",
       "      <td>REINDEER CT &amp; DEAD END;  NEW HANOVER; Station ...</td>\n",
       "      <td>19525.0</td>\n",
       "      <td>EMS: BACK PAINS/INJURY</td>\n",
       "      <td>2015-12-10 17:10:52</td>\n",
       "      <td>NEW HANOVER</td>\n",
       "      <td>REINDEER CT &amp; DEAD END</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40.258061</td>\n",
       "      <td>-75.264680</td>\n",
       "      <td>BRIAR PATH &amp; WHITEMARSH LN;  HATFIELD TOWNSHIP...</td>\n",
       "      <td>19446.0</td>\n",
       "      <td>EMS: DIABETIC EMERGENCY</td>\n",
       "      <td>2015-12-10 17:29:21</td>\n",
       "      <td>HATFIELD TOWNSHIP</td>\n",
       "      <td>BRIAR PATH &amp; WHITEMARSH LN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.121182</td>\n",
       "      <td>-75.351975</td>\n",
       "      <td>HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...</td>\n",
       "      <td>19401.0</td>\n",
       "      <td>Fire: GAS-ODOR/LEAK</td>\n",
       "      <td>2015-12-10 14:39:21</td>\n",
       "      <td>NORRISTOWN</td>\n",
       "      <td>HAWS AVE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.116153</td>\n",
       "      <td>-75.343513</td>\n",
       "      <td>AIRY ST &amp; SWEDE ST;  NORRISTOWN; Station 308A;...</td>\n",
       "      <td>19401.0</td>\n",
       "      <td>EMS: CARDIAC EMERGENCY</td>\n",
       "      <td>2015-12-10 16:47:36</td>\n",
       "      <td>NORRISTOWN</td>\n",
       "      <td>AIRY ST &amp; SWEDE ST</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.251492</td>\n",
       "      <td>-75.603350</td>\n",
       "      <td>CHERRYWOOD CT &amp; DEAD END;  LOWER POTTSGROVE; S...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>EMS: DIZZINESS</td>\n",
       "      <td>2015-12-10 16:56:52</td>\n",
       "      <td>LOWER POTTSGROVE</td>\n",
       "      <td>CHERRYWOOD CT &amp; DEAD END</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat        lng                                               desc  \\\n",
       "0  40.297876 -75.581294  REINDEER CT & DEAD END;  NEW HANOVER; Station ...   \n",
       "1  40.258061 -75.264680  BRIAR PATH & WHITEMARSH LN;  HATFIELD TOWNSHIP...   \n",
       "2  40.121182 -75.351975  HAWS AVE; NORRISTOWN; 2015-12-10 @ 14:39:21-St...   \n",
       "3  40.116153 -75.343513  AIRY ST & SWEDE ST;  NORRISTOWN; Station 308A;...   \n",
       "4  40.251492 -75.603350  CHERRYWOOD CT & DEAD END;  LOWER POTTSGROVE; S...   \n",
       "\n",
       "       zip                    title            timeStamp                twp  \\\n",
       "0  19525.0   EMS: BACK PAINS/INJURY  2015-12-10 17:10:52        NEW HANOVER   \n",
       "1  19446.0  EMS: DIABETIC EMERGENCY  2015-12-10 17:29:21  HATFIELD TOWNSHIP   \n",
       "2  19401.0      Fire: GAS-ODOR/LEAK  2015-12-10 14:39:21         NORRISTOWN   \n",
       "3  19401.0   EMS: CARDIAC EMERGENCY  2015-12-10 16:47:36         NORRISTOWN   \n",
       "4      NaN           EMS: DIZZINESS  2015-12-10 16:56:52   LOWER POTTSGROVE   \n",
       "\n",
       "                         addr  e  \n",
       "0      REINDEER CT & DEAD END  1  \n",
       "1  BRIAR PATH & WHITEMARSH LN  1  \n",
       "2                    HAWS AVE  1  \n",
       "3          AIRY ST & SWEDE ST  1  \n",
       "4    CHERRYWOOD CT & DEAD END  1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from pandas import Series\n",
    "from geopy.geocoders import Nominatim\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#importing the dataset using pandas\n",
    "df = pd.read_csv(\"./911.csv\")\n",
    "\n",
    "#sample of original dataset\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#separate timeStamp data into 2 new columns\n",
    "df['date'] = df.timeStamp.str[0:11]\n",
    "df['time'] = df.timeStamp.str[-8:]\n",
    "\n",
    "#Get rid of dummy 'e' column and 'timeStamp' column\n",
    "del df['e']\n",
    "del df['timeStamp']\n",
    "#If time at end, then try to extract station number and impute\n",
    "del df['desc']\n",
    "\n",
    "#sample of dataset\n",
    "#df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat      177755\n",
       "lng      177755\n",
       "zip      155957\n",
       "title    177755\n",
       "twp      177694\n",
       "addr     177755\n",
       "date     177755\n",
       "time     177755\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count number of values in each column\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21822"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finds total number of rows with missing values \n",
    "#Rows with more than one missing value only counted once\n",
    "df.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat      155957\n",
       "lng      155957\n",
       "zip      155957\n",
       "title    155957\n",
       "twp      155933\n",
       "addr     155957\n",
       "date     155957\n",
       "time     155957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop rows with missing zipcode values\n",
    "df = df.dropna(subset=['zip'])\n",
    "\n",
    "#Convert float values for zipcodes to integer type\n",
    "df['zip'] = df['zip'].astype(int)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPPER MORELAND\n",
      "WARRINGTON\n",
      "NORRISTOWN\n",
      "NORRISTOWN\n",
      "MONTGOMERY\n",
      "UPPER MERION\n",
      "TOWAMENCIN\n",
      "HATBORO\n",
      "HORSHAM\n",
      "HATFIELD\n",
      "JENKINTOWN\n",
      "LOWER MERION\n",
      "FRANCONIA\n",
      "HATBORO\n",
      "POTTSTOWN\n",
      "SKIPPACK\n",
      "SKIPPACK\n",
      "UPPER MORELAND\n",
      "NORRISTOWN\n",
      "NORRISTOWN\n",
      "UPPER SALFORD\n",
      "SPRINGFIELD\n",
      "UPPER MERION\n",
      "UPPER PROVIDENCE\n"
     ]
    }
   ],
   "source": [
    "empty = np.where(pd.isnull(df))\n",
    "geolocator = Nominatim()\n",
    "index = 0\n",
    "\n",
    "\n",
    "#Impute 24 missing township values\n",
    "for i in np.nditer(empty):\n",
    "    \n",
    "    #row of missing township cell\n",
    "    row = empty[0][index] \n",
    "    #column of missing township cell\n",
    "    column = empty[1][index]\n",
    "    \n",
    "    \n",
    "    temp_lat = repr(df.iloc[row,0])\n",
    "    temp_long = repr(df.iloc[row,1])\n",
    "    \n",
    "    \n",
    "    location = geolocator.reverse([temp_lat, temp_long], timeout = 60)\n",
    "    \n",
    "    if column == 4:\n",
    "        \n",
    "    \n",
    "        #extract township value from location dictionary\n",
    "        town = location.raw['address']['city'] \n",
    "    \n",
    "    \n",
    "        #remove 'Township' ending from name of town    \n",
    "        if town.endswith(\"Township\"):\n",
    "            town = town[0:-9]\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "                \n",
    "        #convert to uppercase to maintain township format in dataframe    \n",
    "        town = town.upper()\n",
    "    \n",
    "        #put imputed township name into corresponding missing cell of dataframe\n",
    "        df.iloc[row, column] = town\n",
    "    \n",
    "        print(df.iloc[row, column])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        pass\n",
    "        \n",
    "        #Elected to comment out code to impute missing zipcodes because it would take too long (approx. 4-6 hrs.)\n",
    "        #zcode = location.raw['address']['postcode']\n",
    "        \n",
    "        #df.iloc[row, column] = zcode\n",
    "        \n",
    "        #print(df.iloc[row, column])\n",
    "    \n",
    "        \n",
    "    #increment index to get to next set of index values for empty township cell\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat      155957\n",
       "lng      155957\n",
       "zip      155957\n",
       "title    155957\n",
       "twp      155957\n",
       "addr     155957\n",
       "date     155957\n",
       "time     155957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hour = df.time.str[0:2]\n",
    "hour2 = pd.to_numeric(hour)\n",
    "\n",
    "#If time of call is between 6PM and 6AM then it is classified as 'night', otherwise it is classified as 'day'\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    if(hour2.loc[i] >= 18 or hour2.loc[i] < 6):\n",
    "        hour.at[i] = 'night'\n",
    "    else:\n",
    "        hour.at[i] = 'day'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Replace military time with either 'night' or 'day'\n",
    "del df['time']\n",
    "\n",
    "df['time_of_day'] = hour\n",
    "\n",
    "#df.head(10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change date format to weekdays format\n",
    "df['dates'] = pd.to_datetime(df['date'])\n",
    "df['weekday'] = df['dates'].dt.weekday_name\n",
    "\n",
    "del df['date']\n",
    "del df['dates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Separate first part of 911 call classification from rest of title\n",
    "df['class'], df['title2'] = df['title'].str.split(':', 1).str\n",
    "del df['title']\n",
    "del df['title2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#unique zipcodes in the dataset\n",
    "df.zip.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the number of unique zipcodes\n",
    "s = Series(df.zip)\n",
    "zip_unique = s.unique().size\n",
    "print(zip_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#unique townships in the dataset\n",
    "df.twp.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the number of unique townships\n",
    "s2 = Series(df.twp)\n",
    "twp_unique = s2.unique().size\n",
    "print(twp_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find the number of unique address locations\n",
    "s4 = Series(df.addr)\n",
    "s4.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLat = Series(df.lat)\n",
    "sLat.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLong = Series(df.lng)\n",
    "sLong.unique().size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLat.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLat.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLong.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sLong.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change string data to label encoded integers for RandomForestClassifier()\n",
    "le_dow = preprocessing.LabelEncoder()\n",
    "le_tod = preprocessing.LabelEncoder()\n",
    "le_addr = preprocessing.LabelEncoder()\n",
    "le_twp = preprocessing.LabelEncoder()\n",
    "le_class = preprocessing.LabelEncoder()\n",
    "\n",
    "le_dow = le_dow.fit_transform(df['weekday'])\n",
    "le_tod = le_tod.fit_transform(df['time_of_day'])\n",
    "le_addr = le_addr.fit_transform(df['addr'])\n",
    "le_twp = le_twp.fit_transform(df['twp'])\n",
    "le_class = le_class.fit_transform(df['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create copy of dataframe\n",
    "df2 = df\n",
    "\n",
    "#Delete old columns with string values and replace with new label encoded columns\n",
    "del df2['weekday']\n",
    "del df2['time_of_day']\n",
    "del df2['addr']\n",
    "del df2['twp']\n",
    "del df2['class']\n",
    "\n",
    "\n",
    "df2['weekday'] = le_dow\n",
    "df2['time_of_day'] = le_tod\n",
    "df2['addr'] = le_addr\n",
    "df2['twp'] = le_twp\n",
    "df2['class'] = le_class\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split attributes for prediction input and classification attribute\n",
    "x = df2[['lat', 'lng', 'zip', 'twp', 'addr', 'time_of_day', 'weekday']].copy()\n",
    "y = df2[['class']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split into training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, stratify=y, random_state=42)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=100, criterion='entropy', max_features=5, max_depth=25, min_impurity_split=1e-1, n_jobs=-1, random_state=0)\n",
    "\n",
    "#Create random forest classifier with data\n",
    "forest.fit(x_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy on training set: {:.3f}\".format(forest.score(x_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(forest.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "important = forest.feature_importances_\n",
    "print 'Feature importance:\\n'\n",
    "\n",
    "for i in range(7):\n",
    "    print df2.columns.values[i],': ',important[i], '\\n'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_features = 7\n",
    "names = []\n",
    "\n",
    "for i in range(n_features):\n",
    "    names.append(df2.columns.values[i])\n",
    "\n",
    "plt.barh(range(n_features), forest.feature_importances_, align='center')\n",
    "plt.yticks(np.arange(n_features), names)\n",
    "plt.xlabel(\"911 Dataset Feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
